{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d21cf9a-5892-4036-b308-d1ef8dafc5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import random\n",
    "from surprise import Reader, Dataset\n",
    "from surprise.model_selection import train_test_split, cross_validate, GridSearchCV\n",
    "from surprise import KNNBasic, KNNWithMeans, KNNWithZScore, KNNBaseline, SVD\n",
    "from surprise import accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ab41e30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random sampling of data: To be done only once\n",
    "\n",
    "# df = pd.read_csv(\"okcupid_profiles.csv\")\n",
    "# weights = {\n",
    "#     ('straight', 'm'): 1,\n",
    "#     ('straight', 'f'): 1,\n",
    "#     ('gay', 'm'): 0.5,\n",
    "#     ('gay', 'f'): 0.5,\n",
    "#     ('bisexual', 'm'): 0.5,\n",
    "#     ('bisexual', 'f'): 0.5\n",
    "# }\n",
    "# n = 10000\n",
    "# # Calculate the weight for each row based on orientation and sex\n",
    "# df['weight'] = df.apply(lambda row: weights.get((row['orientation'], row['sex']), 0), axis=1)\n",
    "\n",
    "# # Sample n rows with replacement based on the weights\n",
    "# sampled_df = df.sample(n=n, replace=True, weights='weight')\n",
    "\n",
    "# # Drop the weight column\n",
    "# sampled_df.drop(columns=['weight'], inplace=True)\n",
    "\n",
    "# sampled_df.count()\n",
    "# group_counts = sampled_df.groupby(['orientation', 'sex']).size()\n",
    "# print(group_counts)\n",
    "# # sampled_df.to_csv('okcupid_profile_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07f4995c-0f84-4647-b7ea-d1d1bdaca805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orientation  sex\n",
      "bisexual     f       178\n",
      "             m        69\n",
      "gay          f       142\n",
      "             m       387\n",
      "straight     f      3676\n",
      "             m      5548\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"okcupid_profile_data.csv\")\n",
    "dataset.insert(0, 'ID', range(0, len(dataset)))\n",
    "\n",
    "dataset.head()\n",
    "dataset.count()\n",
    "dataset['orientation'].unique()\n",
    "dataset.isnull().sum()\n",
    "\n",
    "group_counts = dataset.groupby(['orientation', 'sex']).size()\n",
    "print(group_counts)\n",
    "# dataset['sex'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00ae1692-44ef-4b40-a17b-96b8c0134b79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>age</th>\n",
       "      <th>status</th>\n",
       "      <th>sex</th>\n",
       "      <th>orientation</th>\n",
       "      <th>body_type</th>\n",
       "      <th>diet</th>\n",
       "      <th>drinks</th>\n",
       "      <th>drugs</th>\n",
       "      <th>education</th>\n",
       "      <th>...</th>\n",
       "      <th>essay1</th>\n",
       "      <th>essay2</th>\n",
       "      <th>essay3</th>\n",
       "      <th>essay4</th>\n",
       "      <th>essay5</th>\n",
       "      <th>essay6</th>\n",
       "      <th>essay7</th>\n",
       "      <th>essay8</th>\n",
       "      <th>essay9</th>\n",
       "      <th>possible_match_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>fit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>socially</td>\n",
       "      <td>NaN</td>\n",
       "      <td>graduated from masters program</td>\n",
       "      <td>...</td>\n",
       "      <td>i do the corporate tech industry grind at an a...</td>\n",
       "      <td>what am i not good at? i am a jack of all trad...</td>\n",
       "      <td>i'm going to go with humor. or that i am just ...</td>\n",
       "      <td>film: robert altman, coen brothers, terry gill...</td>\n",
       "      <td>well, when the world goes into economic and po...</td>\n",
       "      <td>art/film projects, the world's politics and ec...</td>\n",
       "      <td>lounging around the house watching tv/movie, e...</td>\n",
       "      <td>well, it's really not that private, but i weav...</td>\n",
       "      <td>if the above seems interesting and you fit at ...</td>\n",
       "      <td>[3, 4, 9, 10, 11, 12, 14, 17, 18, 19, 21, 24, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>athletic</td>\n",
       "      <td>mostly anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>graduated from masters program</td>\n",
       "      <td>...</td>\n",
       "      <td>right now i'm working on my ph.d. in stanford....</td>\n",
       "      <td>listening to people. learning new skills. tole...</td>\n",
       "      <td>i got a twin brother who also does his ph.d. a...</td>\n",
       "      <td>books: generally investigative journalism movi...</td>\n",
       "      <td>music friends sunshine ice cream sports iphone</td>\n",
       "      <td>...how to make people laugh ...how to make the...</td>\n",
       "      <td>...up for anything but staying at home!</td>\n",
       "      <td>ask me.</td>\n",
       "      <td>you wanna know more about me :)</td>\n",
       "      <td>[3, 4, 9, 10, 11, 12, 14, 17, 18, 19, 21, 24, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>fit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>working on masters program</td>\n",
       "      <td>...</td>\n",
       "      <td>finishing graduate school. will be going for a...</td>\n",
       "      <td>cooking italian/roman specialties, translating...</td>\n",
       "      <td>easy going, white teeth, nice shoes.</td>\n",
       "      <td>movies: bill and ted's excellent adventure, th...</td>\n",
       "      <td>family and friends strong coffee music beads o...</td>\n",
       "      <td>it might sound cliche but its true: how to liv...</td>\n",
       "      <td>ideally a live music show or having dinner wit...</td>\n",
       "      <td>have three visible scars on my body.</td>\n",
       "      <td>you want to leisurely enjoy sf, want to get a ...</td>\n",
       "      <td>[3, 4, 9, 10, 11, 12, 14, 17, 18, 19, 21, 24, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>single</td>\n",
       "      <td>f</td>\n",
       "      <td>straight</td>\n",
       "      <td>average</td>\n",
       "      <td>NaN</td>\n",
       "      <td>not at all</td>\n",
       "      <td>never</td>\n",
       "      <td>graduated from college/university</td>\n",
       "      <td>...</td>\n",
       "      <td>i've been in real estate for most of my career...</td>\n",
       "      <td>salsa dancing, hula hooping, singing, dancing ...</td>\n",
       "      <td>that i can get along and find something in com...</td>\n",
       "      <td>books: too many to list! angela's ashes, ready...</td>\n",
       "      <td>lucy the greatest dog ever live music stimulat...</td>\n",
       "      <td>the present, the next fun thing, my career, my...</td>\n",
       "      <td>salsa dancing or dancing with friends, going t...</td>\n",
       "      <td>when i'm in a really good mood, or if im in a ...</td>\n",
       "      <td>you aren't at all sneaky creepy ... you're pas...</td>\n",
       "      <td>[0, 1, 2, 5, 6, 7, 8, 13, 15, 16, 20, 22, 23, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>single</td>\n",
       "      <td>f</td>\n",
       "      <td>straight</td>\n",
       "      <td>average</td>\n",
       "      <td>mostly anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>NaN</td>\n",
       "      <td>graduated from college/university</td>\n",
       "      <td>...</td>\n",
       "      <td>well i just got a job working as a program spe...</td>\n",
       "      <td>directions! my friends and family joke that i'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>books: harry potter, nicholas sparks books (gu...</td>\n",
       "      <td>family friends books music i'll come up with t...</td>\n",
       "      <td>the power of our thoughts. and now that i just...</td>\n",
       "      <td>probably enjoying a quiet night to wind down f...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>~ you made it this far ~ you're looking for so...</td>\n",
       "      <td>[0, 1, 2, 5, 6, 7, 8, 13, 15, 16, 20, 22, 23, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  age  status sex orientation body_type             diet      drinks  \\\n",
       "0   0   35  single   m    straight       fit              NaN    socially   \n",
       "1   1   27  single   m    straight  athletic  mostly anything    socially   \n",
       "2   2   31  single   m    straight       fit              NaN    socially   \n",
       "3   3   28  single   f    straight   average              NaN  not at all   \n",
       "4   4   24  single   f    straight   average  mostly anything    socially   \n",
       "\n",
       "   drugs                          education  ...  \\\n",
       "0    NaN     graduated from masters program  ...   \n",
       "1  never     graduated from masters program  ...   \n",
       "2  never         working on masters program  ...   \n",
       "3  never  graduated from college/university  ...   \n",
       "4    NaN  graduated from college/university  ...   \n",
       "\n",
       "                                              essay1  \\\n",
       "0  i do the corporate tech industry grind at an a...   \n",
       "1  right now i'm working on my ph.d. in stanford....   \n",
       "2  finishing graduate school. will be going for a...   \n",
       "3  i've been in real estate for most of my career...   \n",
       "4  well i just got a job working as a program spe...   \n",
       "\n",
       "                                              essay2  \\\n",
       "0  what am i not good at? i am a jack of all trad...   \n",
       "1  listening to people. learning new skills. tole...   \n",
       "2  cooking italian/roman specialties, translating...   \n",
       "3  salsa dancing, hula hooping, singing, dancing ...   \n",
       "4  directions! my friends and family joke that i'...   \n",
       "\n",
       "                                              essay3  \\\n",
       "0  i'm going to go with humor. or that i am just ...   \n",
       "1  i got a twin brother who also does his ph.d. a...   \n",
       "2               easy going, white teeth, nice shoes.   \n",
       "3  that i can get along and find something in com...   \n",
       "4                                                NaN   \n",
       "\n",
       "                                              essay4  \\\n",
       "0  film: robert altman, coen brothers, terry gill...   \n",
       "1  books: generally investigative journalism movi...   \n",
       "2  movies: bill and ted's excellent adventure, th...   \n",
       "3  books: too many to list! angela's ashes, ready...   \n",
       "4  books: harry potter, nicholas sparks books (gu...   \n",
       "\n",
       "                                              essay5  \\\n",
       "0  well, when the world goes into economic and po...   \n",
       "1     music friends sunshine ice cream sports iphone   \n",
       "2  family and friends strong coffee music beads o...   \n",
       "3  lucy the greatest dog ever live music stimulat...   \n",
       "4  family friends books music i'll come up with t...   \n",
       "\n",
       "                                              essay6  \\\n",
       "0  art/film projects, the world's politics and ec...   \n",
       "1  ...how to make people laugh ...how to make the...   \n",
       "2  it might sound cliche but its true: how to liv...   \n",
       "3  the present, the next fun thing, my career, my...   \n",
       "4  the power of our thoughts. and now that i just...   \n",
       "\n",
       "                                              essay7  \\\n",
       "0  lounging around the house watching tv/movie, e...   \n",
       "1            ...up for anything but staying at home!   \n",
       "2  ideally a live music show or having dinner wit...   \n",
       "3  salsa dancing or dancing with friends, going t...   \n",
       "4  probably enjoying a quiet night to wind down f...   \n",
       "\n",
       "                                              essay8  \\\n",
       "0  well, it's really not that private, but i weav...   \n",
       "1                                            ask me.   \n",
       "2               have three visible scars on my body.   \n",
       "3  when i'm in a really good mood, or if im in a ...   \n",
       "4                                                NaN   \n",
       "\n",
       "                                              essay9  \\\n",
       "0  if the above seems interesting and you fit at ...   \n",
       "1                    you wanna know more about me :)   \n",
       "2  you want to leisurely enjoy sf, want to get a ...   \n",
       "3  you aren't at all sneaky creepy ... you're pas...   \n",
       "4  ~ you made it this far ~ you're looking for so...   \n",
       "\n",
       "                                  possible_match_ids  \n",
       "0  [3, 4, 9, 10, 11, 12, 14, 17, 18, 19, 21, 24, ...  \n",
       "1  [3, 4, 9, 10, 11, 12, 14, 17, 18, 19, 21, 24, ...  \n",
       "2  [3, 4, 9, 10, 11, 12, 14, 17, 18, 19, 21, 24, ...  \n",
       "3  [0, 1, 2, 5, 6, 7, 8, 13, 15, 16, 20, 22, 23, ...  \n",
       "4  [0, 1, 2, 5, 6, 7, 8, 13, 15, 16, 20, 22, 23, ...  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adding possible matches according to sex and orientation : not required\n",
    "\n",
    "males = list(dataset[dataset['sex'] == 'm'][\"ID\"])\n",
    "females = list(dataset[dataset['sex'] == 'f'][\"ID\"])\n",
    "both = males + females\n",
    "\n",
    "dataset['possible_match_ids'] = dataset.apply(lambda row:  \n",
    "                                         females if row['sex'] == 'm' and row['orientation'] == 'straight' \n",
    "                                         else (males if row['sex'] == 'f' and row['orientation'] == 'straight'\n",
    "                                            else (males if row['sex'] == 'm' and row['orientation'] == 'gay'\n",
    "                                                else (females if row['sex'] == 'f' and row['orientation'] == 'gay'\n",
    "                                                    else both      \n",
    "                                                     )))\n",
    "                                         , axis=1)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3756f98-07a5-4649-902f-7a76bb614741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read compatibility scores from file\n",
    "\n",
    "import json\n",
    "comp_scores = \"compatibility.json\"\n",
    "with open(comp_scores) as f:\n",
    "    comp_scores = json.loads(f.read())\n",
    "\n",
    "def get_dict(row):\n",
    "    return comp_scores.get(str(row['ID']), {})\n",
    "\n",
    "# Adding new column with corresponding dictionary\n",
    "dataset['top_compatible'] = dataset.apply(get_dict, axis=1)\n",
    "test_dataset = dataset[dataset['top_compatible'] != {}]\n",
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7abf2a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add random compatibility scores - temp solution\n",
    "def get_dict(row):\n",
    "    index = [random.randint(0, 9999) for _ in range(50)]\n",
    "    score = [random.random() for _ in range(50)]\n",
    "    return({'index':index, 'score':score})\n",
    "\n",
    "dataset['top_compatible'] = dataset.apply(get_dict, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f807e9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generating compatibility dataset of size n * 50\n",
    "compatibility_data = {'ID': [], 'compatible_ID': [], 'compatibility_score': []}\n",
    "for index, row in dataset.iterrows():\n",
    "    id_value = row['ID']\n",
    "    compatible_ids = row['top_compatible']['index']\n",
    "    compatibility_scores = row['top_compatible']['score']\n",
    "    \n",
    "    # Appending data for each compatible ID\n",
    "    for compatible_id, compatibility_score in zip(compatible_ids, compatibility_scores):\n",
    "        compatibility_data['ID'].append(id_value)\n",
    "        compatibility_data['compatible_ID'].append(compatible_id)\n",
    "        compatibility_data['compatibility_score'].append(compatibility_score)\n",
    "\n",
    "compatibility_data = pd.DataFrame(compatibility_data)\n",
    "# compatibility_data.head()\n",
    "len(compatibility_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d4ecbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a surprise object\n",
    "\n",
    "reader = Reader(rating_scale=(0, 1))\n",
    "data   = Dataset.load_from_df(compatibility_data, reader)\n",
    "\n",
    "\n",
    "# Split the data into training & testing sets. Python's surprise documentation has the steps detailed out\n",
    "# https://surprise.readthedocs.io/en/stable/FAQ.html\n",
    "\n",
    "raw_ratings = data.raw_ratings\n",
    "random.shuffle(raw_ratings)                 # shuffle dataset\n",
    "\n",
    "threshold   = int(len(raw_ratings)*0.8)\n",
    "\n",
    "train_raw_ratings = raw_ratings[:threshold] # 80% of data is trainset\n",
    "test_raw_ratings  = raw_ratings[threshold:] # 20% of data is testset\n",
    "\n",
    "data.raw_ratings = train_raw_ratings        # data is now the trainset\n",
    "trainset         = data.build_full_trainset() \n",
    "testset          = data.construct_testset(test_raw_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d13f8da6-1c23-442e-b1ff-e438ccc9e140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying KNN (K-Nearest Neighbors) & SVD (Singluar Value decomposition) algorithms using default model parameters\n",
    "\n",
    "models=[KNNBasic(),KNNWithMeans(),KNNWithZScore(),KNNBaseline(),SVD()] \n",
    "results = {}\n",
    "\n",
    "for model in models:\n",
    "    # perform 5 fold cross validation\n",
    "    # evaluation metrics: mean absolute error & root mean square error\n",
    "    CV_scores = cross_validate(model, data, measures=[\"MAE\",\"RMSE\"], cv=5, n_jobs=-1)  \n",
    "    \n",
    "    # storing the average score across the 5 fold cross validation for each model\n",
    "    result = pd.DataFrame.from_dict(CV_scores).mean(axis=0).\\\n",
    "             rename({'test_mae':'MAE', 'test_rmse': 'RMSE'})\n",
    "    results[str(model).split(\"algorithms.\")[1].split(\"object \")[0]] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22ffbf22-1ee9-4ea8-af38-4822c2d4956d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>test_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>matrix_factorization.SVD</th>\n",
       "      <td>0.262844</td>\n",
       "      <td>0.309838</td>\n",
       "      <td>3.025808</td>\n",
       "      <td>0.551444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knns.KNNBasic</th>\n",
       "      <td>0.283953</td>\n",
       "      <td>0.342702</td>\n",
       "      <td>3.243219</td>\n",
       "      <td>2.147061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knns.KNNBaseline</th>\n",
       "      <td>0.284609</td>\n",
       "      <td>0.343441</td>\n",
       "      <td>2.908174</td>\n",
       "      <td>2.261356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knns.KNNWithZScore</th>\n",
       "      <td>0.284818</td>\n",
       "      <td>0.344020</td>\n",
       "      <td>2.966284</td>\n",
       "      <td>2.224580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knns.KNNWithMeans</th>\n",
       "      <td>0.285346</td>\n",
       "      <td>0.344542</td>\n",
       "      <td>2.710480</td>\n",
       "      <td>2.061376</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                MAE      RMSE  fit_time  test_time\n",
       "matrix_factorization.SVD   0.262844  0.309838  3.025808   0.551444\n",
       "knns.KNNBasic              0.283953  0.342702  3.243219   2.147061\n",
       "knns.KNNBaseline           0.284609  0.343441  2.908174   2.261356\n",
       "knns.KNNWithZScore         0.284818  0.344020  2.966284   2.224580\n",
       "knns.KNNWithMeans          0.285346  0.344542  2.710480   2.061376"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_df = pd.DataFrame.from_dict(results)\n",
    "print(\"Model Performance: \\n\")\n",
    "performance_df.T.sort_values(by='RMSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c9b64ba-b73f-45dc-a4f3-cb8353ab55f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(0, 1))\n",
    "data = Dataset.load_from_df(compatibility_data, reader)\n",
    "trainset = data.build_full_trainset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94ed9d1f-3f09-422e-8e93-4207582bd853",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_recommendationsKNN(userID=13552, like_recommend=5, get_recommend =10):\n",
    "    \n",
    "    ''' This function generates \"get_recommend\" number of book recommendations using \n",
    "        KNNWithMeans & item based filtering. The function needs as input three \n",
    "        different parameters:\n",
    "        (1) userID i.e., userID for which recommendations need to be generated \n",
    "        (2) like_recommend i.e., number of top recommendations for the userID to be \n",
    "        considered for making recommendations \n",
    "        (3) get_recommend i.e., number of recommendations to generate for the userID\n",
    "        Default values are: userID=13552, like_recommend=5, get_recommend=10\n",
    "    '''\n",
    "    \n",
    "    # Compute item based similarity matrix\n",
    "    sim_options       = {'name':'cosine','min_support':3,'user_based':True}\n",
    "    similarity_matrix = KNNWithMeans(sim_options=sim_options).fit(trainset).\\\n",
    "                        compute_similarities() \n",
    "    \n",
    "    userID      = trainset.to_inner_uid(userID)    # converts the raw userID to innerID\n",
    "    userRatings = trainset.ur[userID]              # method .ur takes user innerID & \n",
    "                                                   # returns back user ratings\n",
    "    \n",
    "    \n",
    "    # userRatings is a list of tuples [(,),(,),(,)..]. Each tuple contains item & rating\n",
    "    # given by the user for that item. Next, the tuples will be sorted within the list \n",
    "    # in decreasing order of rating. Then top 'like_recommend' items & ratings are extracted\n",
    "    \n",
    "    temp_df = pd.DataFrame(userRatings).sort_values(by=1, ascending=False).\\\n",
    "              head(like_recommend)\n",
    "    userRatings = temp_df.to_records(index=False) \n",
    "    \n",
    "    # for each (item,rating) in top like_recommend user items, multiply the user rating for\n",
    "    # the item with the similarity score (later is obtained from item similarity_matrix) for\n",
    "    # all items. This helps calculate the weighted rating for all items. The weighted ratings \n",
    "    # are added & divided by sum of weights to estimate rating the user would give an item\n",
    "    \n",
    "    recommendations   = {}\n",
    "\n",
    "    for user_top_item, user_top_item_rating  in userRatings:\n",
    "\n",
    "        all_item_indices          =   list(pd.DataFrame(similarity_matrix)[user_top_item].index)\n",
    "        all_item_weighted_rating  =   list(pd.DataFrame(similarity_matrix)[user_top_item].values*\\\n",
    "                                          user_top_item_rating)\n",
    "        \n",
    "        all_item_weights          =   list(pd.DataFrame(similarity_matrix)[user_top_item].values)\n",
    "        \n",
    "        \n",
    "        # All items & final estimated ratings are added to a dictionary called recommendations\n",
    "        \n",
    "        for index in range(len(all_item_indices)):\n",
    "            if index in recommendations:\n",
    "                # sum of weighted ratings\n",
    "                recommendations[index] += all_item_weighted_rating[index]        \n",
    "            else:                        \n",
    "                recommendations[index]  = all_item_weighted_rating[index]\n",
    "\n",
    "    \n",
    "    for index in range(len(all_item_indices)):                               \n",
    "            if all_item_weights[index]  !=0:\n",
    "                # final ratings (sum of weighted ratings/sum of weights)\n",
    "                recommendations[index]   =recommendations[index]/\\\n",
    "                                          (all_item_weights[index]*like_recommend)\n",
    "                      \n",
    "\n",
    "    # convert dictionary recommendations to a be a list of tuples [(,),(,),(,)]\n",
    "    # with each tuple being an item & estimated rating user would give that item\n",
    "    # sort the tuples within the list to be in decreasing order of estimated ratings\n",
    "\n",
    "    temp_df = pd.Series(recommendations).reset_index().sort_values(by=0, ascending=False)\n",
    "    recommendations = list(temp_df.to_records(index=False))\n",
    "    \n",
    "    # return get_recommend number of recommedations (only return items the user \n",
    "    # has not previously rated)\n",
    "    \n",
    "    final_recommendations = []\n",
    "    count = 0\n",
    "    \n",
    "    for item, score in recommendations:\n",
    "        flag = True\n",
    "        for userItem, userRating in trainset.ur[userID]:\n",
    "            if item == userItem: \n",
    "                flag = False       # If item in recommendations has not been rated by user, \n",
    "                break              # add to final_recommendations\n",
    "        if flag == True:\n",
    "            final_recommendations.append(trainset.to_raw_iid(item)) \n",
    "            count +=1              # trainset has the items stored as inner id,  \n",
    "                                   # convert to raw id & append \n",
    "            \n",
    "        if count > get_recommend:  # Only get 'get_recommend' number of recommendations\n",
    "            break\n",
    "    \n",
    "    return(final_recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cbad4583-877b-439f-ac27-9051a6574439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[8664, 2562, 5515, 4448, 749, 1755, 1575, 8485, 169, 1217, 3099]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendationsKNN = generate_recommendationsKNN(userID=2, like_recommend=5, get_recommend=10)\n",
    "recommendationsKNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b246dda-6c86-49a2-b8d7-e20f9dda9f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        ID  age     status sex orientation body_type               diet  \\\n",
      "2        2   31     single   m    straight       fit                NaN   \n",
      "21      21   26     single   f    bisexual     curvy  mostly vegetarian   \n",
      "1491  1491   29     single   m    straight       NaN                NaN   \n",
      "2551  2551   41     single   m    straight  athletic       mostly other   \n",
      "3119  3119   43     single   m    straight  athletic                NaN   \n",
      "3455  3455   32     single   m    straight   average                NaN   \n",
      "4145  4145   34     single   m    straight   average    mostly anything   \n",
      "4575  4575   38  available   m    bisexual       NaN                NaN   \n",
      "4870  4870   28     single   m    straight       fit                NaN   \n",
      "7011  7011   32     single   f    straight   average                NaN   \n",
      "7875  7875   30     single   f         gay   average           anything   \n",
      "9707  9707   41     single   m    straight   average  strictly anything   \n",
      "\n",
      "          drinks      drugs                          education  ...  \\\n",
      "2       socially      never         working on masters program  ...   \n",
      "21      socially      never         working on masters program  ...   \n",
      "1491  not at all      never                                NaN  ...   \n",
      "2551    socially  sometimes     graduated from masters program  ...   \n",
      "3119    socially      never     graduated from masters program  ...   \n",
      "3455    socially      never    graduated from two-year college  ...   \n",
      "4145       often        NaN         working on masters program  ...   \n",
      "4575    socially        NaN                                NaN  ...   \n",
      "4870      rarely      never  graduated from college/university  ...   \n",
      "7011    socially        NaN            working on ph.d program  ...   \n",
      "7875    socially      never                                NaN  ...   \n",
      "9707    socially      never              working on space camp  ...   \n",
      "\n",
      "                                                 essay2  \\\n",
      "2     cooking italian/roman specialties, translating...   \n",
      "21    singing (no really...i'm a professional musici...   \n",
      "1491                                                NaN   \n",
      "2551  being present and listening. i'm accountable: ...   \n",
      "3119                                                NaN   \n",
      "3455  listening and mediating. i love giving advice....   \n",
      "4145  organizing events, hosting, connecting people ...   \n",
      "4575  procrastinating, listening, pontificating, snu...   \n",
      "4870  reading people, appreciating the basics, danci...   \n",
      "7011  pretending to be comfortable with parallel par...   \n",
      "7875                       rotating your tires. yep. :)   \n",
      "9707  skiing, cooking, having fun while traveling, a...   \n",
      "\n",
      "                                                 essay3  \\\n",
      "2                  easy going, white teeth, nice shoes.   \n",
      "21    my fro (if i let it out to play), my laugh (it...   \n",
      "1491                                                NaN   \n",
      "2551  i dress most days for speed and functionality,...   \n",
      "3119             my smile and comfortable confidence...   \n",
      "3455                                                NaN   \n",
      "4145  i don't know... no one's ever told me \"the fir...   \n",
      "4575  the braided beard, or perhaps the utilikilt. n...   \n",
      "4870                                            my wit.   \n",
      "7011                            i'm usually smiling. ;)   \n",
      "7875                          my hair. it's impressive.   \n",
      "9707  eyes, i guess, that and my stunning personalit...   \n",
      "\n",
      "                                                 essay4  \\\n",
      "2     movies: bill and ted's excellent adventure, th...   \n",
      "21    music: too many to mention but here area few :...   \n",
      "1491                                                NaN   \n",
      "2551  always reading (right now its the millenium tr...   \n",
      "3119                                                NaN   \n",
      "3455  i love food! i like spicy, i like sushi, i lik...   \n",
      "4145  music: so much stuff... james brown, michael j...   \n",
      "4575  books/authors: oh boy, too many but here goes....   \n",
      "4870  books- franny and zooey / salinger atlas shrug...   \n",
      "7011  books... to kill a mockingbird. the impossible...   \n",
      "7875  books, too many to list. i listen to anything ...   \n",
      "9707  books: here's a few of my favorites... animal ...   \n",
      "\n",
      "                                                 essay5  \\\n",
      "2     family and friends strong coffee music beads o...   \n",
      "21    my sisters my best friends music my laptop (it...   \n",
      "1491                                                NaN   \n",
      "2551  desire, spice in food and life, motion, progre...   \n",
      "3119  my family, my friends, my macbook pro, great w...   \n",
      "3455                                                NaN   \n",
      "4145  music, friends, art, family, nature, exercise,...   \n",
      "4575  actually i'm pretty adaptable, so the only thi...   \n",
      "4870  travel music family / friends goals exercise o...   \n",
      "7011  i try not to get too attached to things, but h...   \n",
      "7875  greenleftpocket (she wrote that in) friends la...   \n",
      "9707  family & friends  red wine  the internets  tac...   \n",
      "\n",
      "                                                 essay6  \\\n",
      "2     it might sound cliche but its true: how to liv...   \n",
      "21    music, new hiking trails i want to explore, ca...   \n",
      "1491                                                NaN   \n",
      "2551                                                NaN   \n",
      "3119                                                NaN   \n",
      "3455                                                NaN   \n",
      "4145  well, art these days. i'm in art school, so ye...   \n",
      "4575  alternative political structures, especially s...   \n",
      "4870               what i'm doing and where i'm headed.   \n",
      "7011  my studies. how to make the world a little bit...   \n",
      "7875  sex oviouslly, my next meal, my next vacation,...   \n",
      "9707              how i can fit more hours into my day.   \n",
      "\n",
      "                                                 essay7  \\\n",
      "2     ideally a live music show or having dinner wit...   \n",
      "21    i play it by ear and keep it diverse and inter...   \n",
      "1491                                                NaN   \n",
      "2551                                                NaN   \n",
      "3119                                                NaN   \n",
      "3455                                                NaN   \n",
      "4145  painting in the studio, hanging with friends a...   \n",
      "4575  i did a lot of going out when i was younger, n...   \n",
      "4870                                                NaN   \n",
      "7011  debating between staying in with friends or ho...   \n",
      "7875  could be out with friends, could be at home wi...   \n",
      "9707  dinner and drinks with friends, a concert, or....   \n",
      "\n",
      "                                                 essay8  \\\n",
      "2                  have three visible scars on my body.   \n",
      "21    for the life of me, i am never wearing a match...   \n",
      "1491                                                NaN   \n",
      "2551  not interested in falling in love but know eve...   \n",
      "3119                                                NaN   \n",
      "3455  i'm a mild social phobic. i'm working on that....   \n",
      "4145  it wouldn't be private if i admitted it here, ...   \n",
      "4575  i want to be the meat in a patrick stewart and...   \n",
      "4870                                                NaN   \n",
      "7011                    if you meet me, you can ask me.   \n",
      "7875  if you wanna know what happens behind closed d...   \n",
      "9707  i got tattooed with a guitar string when i was...   \n",
      "\n",
      "                                                 essay9  \\\n",
      "2     you want to leisurely enjoy sf, want to get a ...   \n",
      "21    you are: a big sweetie, i love considerate con...   \n",
      "1491                                                NaN   \n",
      "2551  you are bored and want to have some fun. never...   \n",
      "3119  you are balanced, down-to-earth, loving, famil...   \n",
      "3455  this is kind of a silly question. why should i...   \n",
      "4145  you want to explore new spots in sf/oakland fo...   \n",
      "4575  -you know great places to go hiking in the bay...   \n",
      "4870  you're equally motivated, passionate, sincere ...   \n",
      "7011                          you think we'd get along.   \n",
      "7875  you have an la face with an oakland booty. you...   \n",
      "9707  you're looking for someone to share adventures...   \n",
      "\n",
      "                                     possible_match_ids  \\\n",
      "2     [3, 4, 9, 10, 11, 12, 14, 17, 18, 19, 21, 24, ...   \n",
      "21    [0, 1, 2, 5, 6, 7, 8, 13, 15, 16, 20, 22, 23, ...   \n",
      "1491  [3, 4, 9, 10, 11, 12, 14, 17, 18, 19, 21, 24, ...   \n",
      "2551  [3, 4, 9, 10, 11, 12, 14, 17, 18, 19, 21, 24, ...   \n",
      "3119  [3, 4, 9, 10, 11, 12, 14, 17, 18, 19, 21, 24, ...   \n",
      "3455  [3, 4, 9, 10, 11, 12, 14, 17, 18, 19, 21, 24, ...   \n",
      "4145  [3, 4, 9, 10, 11, 12, 14, 17, 18, 19, 21, 24, ...   \n",
      "4575  [0, 1, 2, 5, 6, 7, 8, 13, 15, 16, 20, 22, 23, ...   \n",
      "4870  [3, 4, 9, 10, 11, 12, 14, 17, 18, 19, 21, 24, ...   \n",
      "7011  [0, 1, 2, 5, 6, 7, 8, 13, 15, 16, 20, 22, 23, ...   \n",
      "7875  [3, 4, 9, 10, 11, 12, 14, 17, 18, 19, 21, 24, ...   \n",
      "9707  [3, 4, 9, 10, 11, 12, 14, 17, 18, 19, 21, 24, ...   \n",
      "\n",
      "                                         top_compatible  \n",
      "2     {'index': [3990, 1043, 3429, 1106, 7823, 1416,...  \n",
      "21    {'index': [8400, 5300, 2395, 4401, 9556, 5021,...  \n",
      "1491  {'index': [621, 9899, 7840, 689, 7188, 4605, 8...  \n",
      "2551  {'index': [202, 5330, 6227, 1888, 3422, 3229, ...  \n",
      "3119  {'index': [8578, 6260, 6361, 831, 9761, 9633, ...  \n",
      "3455  {'index': [7890, 9536, 2752, 473, 6135, 7477, ...  \n",
      "4145  {'index': [9383, 3656, 2528, 9475, 6905, 7671,...  \n",
      "4575  {'index': [8164, 7146, 2182, 9197, 8855, 4462,...  \n",
      "4870  {'index': [6100, 8189, 4709, 8862, 7461, 8155,...  \n",
      "7011  {'index': [6295, 2355, 8124, 4618, 8736, 3540,...  \n",
      "7875  {'index': [354, 5955, 8130, 7918, 6185, 5176, ...  \n",
      "9707  {'index': [2149, 7744, 3241, 5783, 2388, 9371,...  \n",
      "\n",
      "[12 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "ids_to_match = [2, 4870, 1491, 7875, 7011, 4145, 2551, 9707, 3455, 21, 3119, 4575]\n",
    "matched_rows = dataset[dataset['ID'].isin(ids_to_match)]\n",
    "print(matched_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b034600d-69cb-4ef5-8f0b-7b8056375c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        ID  age     status sex orientation body_type               diet  \\\n",
      "2        2   31     single   m    straight       fit                NaN   \n",
      "169    169   34     single   f    straight       fit  mostly vegetarian   \n",
      "749    749   48     single   f    straight  athletic                NaN   \n",
      "1217  1217   42     single   m    straight       fit  strictly anything   \n",
      "1575  1575   26     single   m    straight       fit    mostly anything   \n",
      "1755  1755   33     single   f    straight   average                NaN   \n",
      "2562  2562   19     single   f    straight   average                NaN   \n",
      "3099  3099   34     single   m    straight   average  mostly vegetarian   \n",
      "4448  4448   32  available   m    straight   average  strictly anything   \n",
      "5515  5515   27     single   f    straight    skinny    mostly anything   \n",
      "8485  8485   27     single   f    straight   average    mostly anything   \n",
      "8664  8664   54     single   m    straight    skinny                NaN   \n",
      "\n",
      "          drinks  drugs                          education  ...  \\\n",
      "2       socially  never         working on masters program  ...   \n",
      "169     socially    NaN                 college/university  ...   \n",
      "749     socially  never                                NaN  ...   \n",
      "1217    socially  never     graduated from masters program  ...   \n",
      "1575    socially  never  graduated from college/university  ...   \n",
      "1755    socially  never     graduated from masters program  ...   \n",
      "2562  not at all  never      working on college/university  ...   \n",
      "3099       often  never     graduated from masters program  ...   \n",
      "4448       often    NaN  dropped out of college/university  ...   \n",
      "5515    socially  never  graduated from college/university  ...   \n",
      "8485    socially  never  graduated from college/university  ...   \n",
      "8664    socially  never          graduated from space camp  ...   \n",
      "\n",
      "                                                 essay2  \\\n",
      "2     cooking italian/roman specialties, translating...   \n",
      "169   making people feel special, writing, trivia, s...   \n",
      "749     being a mom, friend and cooking a yummy dinner!   \n",
      "1217                  cooking, especially italian food.   \n",
      "1575  maintaining and building friendships. i'm alwa...   \n",
      "1755  planning a trip....drinking coffee....going to...   \n",
      "2562  disagreeing being open minded thinking about m...   \n",
      "3099  exhibiting a sense of humor even during the mo...   \n",
      "4448  - being dapper - making people laugh - carryin...   \n",
      "5515                                                NaN   \n",
      "8485                                                NaN   \n",
      "8664  im a good problem solver, great at my job, eve...   \n",
      "\n",
      "                                                 essay3  \\\n",
      "2                  easy going, white teeth, nice shoes.   \n",
      "169                          pretty eyes, pirate smile.   \n",
      "749                            how tall i am. my smile.   \n",
      "1217  the loud laugh, blunt honesty, and the shaved ...   \n",
      "1575  mayyyyyyybe my height, i guess being 6'6 makes...   \n",
      "1755                                                NaN   \n",
      "2562  my serious expression. my willingness to discl...   \n",
      "3099  my boundless energy...and the fact i generally...   \n",
      "4448  my hats and my mustachio. i'm either dressed v...   \n",
      "5515  rude and unfriendly (most of my friends said i...   \n",
      "8485                                                NaN   \n",
      "8664  my 2 left feet on the dance floor, that no mat...   \n",
      "\n",
      "                                                 essay4  \\\n",
      "2     movies: bill and ted's excellent adventure, th...   \n",
      "169   books: historical fiction, biographies, never ...   \n",
      "749                                                 NaN   \n",
      "1217  books: omnivores dilemma, audacity of hope, gi...   \n",
      "1575  i listen to all genres of music but house musi...   \n",
      "1755  books: i am a chick-lit type of gal, but i can...   \n",
      "2562                                                NaN   \n",
      "3099                      so cliched. i'm not answering   \n",
      "4448  i always find this section difficult to fill o...   \n",
      "5515  the latest one for book is 'divergent' series ...   \n",
      "8485                                                NaN   \n",
      "8664  i like oldies music, italian food, more movies...   \n",
      "\n",
      "                                                 essay5  \\\n",
      "2     family and friends strong coffee music beads o...   \n",
      "169   sailboats southern food music facetime yoga ma...   \n",
      "749                         my son, friends and family!   \n",
      "1217  steady wind, an ebb tide, waves, sushi, tequil...   \n",
      "1575  the people i love cheese laughing car (at leas...   \n",
      "1755  friends/family (does that count as one?)  my d...   \n",
      "2562           air food shelter water clothing internet   \n",
      "3099  1. a good book 2. online gaming 3. passport 4....   \n",
      "4448  - my iphone to facilitate my every mission. - ...   \n",
      "5515                                                NaN   \n",
      "8485                                                NaN   \n",
      "8664  my girls, you, sex, a sunny tropical beach, an...   \n",
      "\n",
      "                                                 essay6  \\\n",
      "2     it might sound cliche but its true: how to liv...   \n",
      "169   what to do in case of a major disaster. the ph...   \n",
      "749                                                 NaN   \n",
      "1217  trying to live life more in the present. seems...   \n",
      "1575  my friends, future, sports, traveling, and way...   \n",
      "1755  where i'm going to travel to next. i try to go...   \n",
      "2562  my personal problems. people i don't know very...   \n",
      "3099                        randomness. sometimes work.   \n",
      "4448  how to change the world with design, and how t...   \n",
      "5515  my future, my dream, my family, my guy (when i...   \n",
      "8485                                                NaN   \n",
      "8664  my future, getting away from it all, and wonde...   \n",
      "\n",
      "                                                 essay7  \\\n",
      "2     ideally a live music show or having dinner wit...   \n",
      "169   preparing for the zombie apocalypse. honestly,...   \n",
      "749                                                 NaN   \n",
      "1217  hanging out down at crissy field with my winds...   \n",
      "1575  hanging out with a group of friends, drinking ...   \n",
      "1755  either working, out of town, at home, or hangi...   \n",
      "2562         on the internet, or thinking about things.   \n",
      "3099  i tend to start on one path and then end up on...   \n",
      "4448  either at a local bar, club, or sitting in fro...   \n",
      "5515  working and trying to get out as quickly as i ...   \n",
      "8485                                                NaN   \n",
      "8664  maybe playing softball, unless the game was on...   \n",
      "\n",
      "                                                 essay8  \\\n",
      "2                  have three visible scars on my body.   \n",
      "169   i don't ski and i have never been to burning man.   \n",
      "749                                                 NaN   \n",
      "1217                                                NaN   \n",
      "1575  i like to dance around in my bedroom to boomin...   \n",
      "1755  that i wouldn't admit the most private thing o...   \n",
      "2562                 i'm an empty essay... fill me out.   \n",
      "3099  oh boy this is embarrassing...whenever i come ...   \n",
      "4448  when the mood strikes or the event is appropri...   \n",
      "5515                                                NaN   \n",
      "8485                                                NaN   \n",
      "8664                                                NaN   \n",
      "\n",
      "                                                 essay9  \\\n",
      "2     you want to leisurely enjoy sf, want to get a ...   \n",
      "169   you want to meet up for coffee, cocktails, dog...   \n",
      "749                                                 NaN   \n",
      "1217  the journey is just as important as the destin...   \n",
      "1575       you have a great smile and love to have fun.   \n",
      "1755  you want to chat, learn more about me, want to...   \n",
      "2562                                  you feel like it.   \n",
      "3099                        you'd like to get together.   \n",
      "4448  my partner and i are looking to meet open mind...   \n",
      "5515  you interested and care to write me, i guess ?...   \n",
      "8485                    you have a great sense of humor   \n",
      "8664  you want to talk, laugh, have dinner, a drink,...   \n",
      "\n",
      "                                     possible_match_ids  \\\n",
      "2     [3, 4, 9, 10, 11, 12, 14, 17, 18, 19, 21, 24, ...   \n",
      "169   [0, 1, 2, 5, 6, 7, 8, 13, 15, 16, 20, 22, 23, ...   \n",
      "749   [0, 1, 2, 5, 6, 7, 8, 13, 15, 16, 20, 22, 23, ...   \n",
      "1217  [3, 4, 9, 10, 11, 12, 14, 17, 18, 19, 21, 24, ...   \n",
      "1575  [3, 4, 9, 10, 11, 12, 14, 17, 18, 19, 21, 24, ...   \n",
      "1755  [0, 1, 2, 5, 6, 7, 8, 13, 15, 16, 20, 22, 23, ...   \n",
      "2562  [0, 1, 2, 5, 6, 7, 8, 13, 15, 16, 20, 22, 23, ...   \n",
      "3099  [3, 4, 9, 10, 11, 12, 14, 17, 18, 19, 21, 24, ...   \n",
      "4448  [3, 4, 9, 10, 11, 12, 14, 17, 18, 19, 21, 24, ...   \n",
      "5515  [0, 1, 2, 5, 6, 7, 8, 13, 15, 16, 20, 22, 23, ...   \n",
      "8485  [0, 1, 2, 5, 6, 7, 8, 13, 15, 16, 20, 22, 23, ...   \n",
      "8664  [3, 4, 9, 10, 11, 12, 14, 17, 18, 19, 21, 24, ...   \n",
      "\n",
      "                                         top_compatible  \n",
      "2     {'index': [3990, 1043, 3429, 1106, 7823, 1416,...  \n",
      "169   {'index': [4428, 7779, 6108, 7684, 1490, 1471,...  \n",
      "749   {'index': [9631, 3447, 8490, 1822, 3483, 5606,...  \n",
      "1217  {'index': [8879, 5203, 6285, 8608, 864, 8265, ...  \n",
      "1575  {'index': [2524, 3190, 3243, 4626, 8917, 737, ...  \n",
      "1755  {'index': [592, 5291, 7941, 3834, 7040, 6271, ...  \n",
      "2562  {'index': [3148, 9446, 5992, 2865, 133, 8425, ...  \n",
      "3099  {'index': [9672, 2404, 1727, 4012, 7270, 5308,...  \n",
      "4448  {'index': [1154, 4129, 2447, 6700, 5786, 5364,...  \n",
      "5515  {'index': [1194, 8037, 9339, 6428, 3494, 7323,...  \n",
      "8485  {'index': [2314, 244, 1167, 2329, 946, 565, 24...  \n",
      "8664  {'index': [948, 306, 952, 8783, 5958, 8901, 15...  \n",
      "\n",
      "[12 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "ids_to_match = [2, 8664, 2562, 5515, 4448, 749, 1755, 1575, 8485, 169, 1217, 3099]\n",
    "matched_rows = dataset[dataset['ID'].isin(ids_to_match)]\n",
    "print(matched_rows)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
